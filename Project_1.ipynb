{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmq8hClET1x-"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade scikit-learn # Upgrade scikit-learn to the latest version\n",
        "!pip uninstall -y numpy\n",
        "!pip install numpy\n",
        "\n",
        "!pip install --upgrade pandas\n",
        "!pip install --upgrade matplotlib\n",
        "!pip install --upgrade seaborn\n",
        "!pip install --upgrade sklearn\n",
        "!pip install --upgrade scipy\n",
        "!pip install --upgrade imblearn\n",
        "!pip install --upgrade catboost\n",
        "!pip install --upgrade xgboost\n",
        "!pip install --upgrade numpy==1.23\n",
        "!pip install scikit-learn==1.1.3\n",
        "\n",
        "#import sklearn\n",
        "#print(sklearn.__version__) # Verify the installed version\n",
        "\n",
        "# for EDA\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.colors\n",
        "import matplotlib.ticker as mtick\n",
        "# feature selection\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif,f_regression, f_classif, chi2\n",
        "# feature scaler\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "# for fixing the imbalanced dataset and split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# for model evaluation\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score,mean_squared_error\n",
        "from sklearn.metrics import confusion_matrix, RocCurveDisplay,classification_report # Use RocCurveDisplay instead of plot_roc_curve\n",
        "\n",
        "# models selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "#from sklearn.naive_bayes import GaussianNB # Import GaussianNB class\n",
        "\n",
        "# for the gridsearch\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "0keGYGqvUBH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading data\n",
        "df1 = pd.read_csv('/content/drive/My Drive/diabetes_binary_5050.csv')\n",
        "df2 = pd.read_csv('/content/drive/My Drive/diabetes_binary.csv')\n",
        "\n",
        "print('df1 shape is: {}'.format(df1.shape))\n",
        "print('df2 shape is: {}'.format(df2.shape))"
      ],
      "metadata": {
        "id": "j-ejsCXaUFrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#describing the dataset\n",
        "df2.head()\n",
        "df2.info()"
      ],
      "metadata": {
        "id": "tDIFxipbUGZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking if there missing values\n",
        "df2.isna().sum()\n",
        "df2.describe()\n",
        "\n",
        "#checking for duplicates\n",
        "duplicates = df2[df2.duplicated()]\n",
        "num_duplicates = len(duplicates)\n",
        "print(f\"Number of Duplicate Rows: {num_duplicates}\")\n",
        "duplicates.head()\n",
        "\n",
        "def data_clean(dataframe):\n",
        "    # Define bins and labels for BMI categorization\n",
        "    bins = [0, 18.5, 24.9, 29.9, float('inf')]\n",
        "    labels = [1, 2, 3, 4]\n",
        "\n",
        "    # Drop duplicates and assign BMI bins\n",
        "    df = dataframe.drop_duplicates().assign(BMI_bins=dataframe['BMI'].pipe(pd.cut, bins=bins, labels=labels))\n",
        "\n",
        "    # Reset the index and convert data types\n",
        "    df = df.reset_index(drop=True).astype({'Diabetes_binary': 'uint8','HighBP': 'uint8',\n",
        "    'HighChol': 'uint8',\n",
        "    'CholCheck': 'uint8',\n",
        "    'BMI': 'uint8',\n",
        "    'Smoker': 'uint8',\n",
        "    'Stroke': 'uint8',\n",
        "    'HeartDiseaseorAttack': 'uint8',\n",
        "    'PhysActivity': 'uint8',\n",
        "    'Fruits': 'uint8',\n",
        "    'Veggies': 'uint8',\n",
        "    'HvyAlcoholConsump': 'uint8',\n",
        "    'AnyHealthcare': 'uint8',\n",
        "    'NoDocbcCost': 'uint8',\n",
        "    'GenHlth': 'uint8',\n",
        "    'MentHlth': 'uint8',\n",
        "    'PhysHlth': 'uint8',\n",
        "    'DiffWalk': 'uint8',\n",
        "    'Sex': 'uint8',\n",
        "    'Age': 'uint8',\n",
        "    'Education': 'uint8',\n",
        "    'Income': 'uint8',\n",
        "    'BMI_bins': 'uint8'\n",
        "    })\n",
        "\n",
        "    return df # Indent all lines within the function"
      ],
      "metadata": {
        "id": "8VNuW3ilULzp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}